# 引言

一个合格的模型要达到的三个指标：

1. 精确性
2. 稳定性
3. 业务可解释性

精确性代表着模型预测坏样本的准确率要高，召回率要高，对正样本的误判率要低等等。

稳定性更多是指对不同群体或者随着时间延伸，模型的各项性能的一致程度。

业务可解释性，模型表现出来的趋势最好是能够跟业务的可解释性是相关的。比如银行的信用卡业务中，额度使用率这个变量与逾期率这个因变量之间就有相关性。



对于一个模型来说，入模变量要越少越好，这也是满足「奥卡姆剃刀原理」，在模型的性能相差不大的前提下， 越是简单的模型，相对于复杂的模型的稳定性要更好。



但是，考虑到申请评分卡的客户并不完全都是有「历史交易」相关的变量的，因此除了满足「变量越少越好」这个要求外，其实在业务上也应该增加一些冗余的变量，这样当申请评分卡的用户没有「历史交易」相关的变量的时候，也可以根据「年龄」，「地域」等相关变量去得到一个预测结果。并且纳入更多的变量的话，模型可以应用的客群范围也会比少变量的模型更加广泛。

![image-20200206185605918](https://tva1.sinaimg.cn/large/0082zybpgy1gbn4nxs4kbj311s048js2.jpg)



# 1. 验证和混合矩阵

训练好的模型需要用测试集进行验证。

一般训练好的模型会对测试集的各个样本进行预测出违约的概率，默认以0.5作为临界值，也就是预测违约概率大于0.5的会判定为违约，根据预测结果和真实标签可以组成一个$2\times2$的混淆矩阵。以下就是一个混淆矩阵。

![image-20200206230621782](https://tva1.sinaimg.cn/large/0082zybpgy1gbn4ny8tt9j311409w759.jpg)

几个符号对应的含义分别是：

![image-20200206230701610](https://tva1.sinaimg.cn/large/0082zybpgy1gbn4nv9orqj31140d640l.jpg)

图10.1表示的是预测为正常的概率，正常概率的计算：

$$Prob(正常)=1-Prob(违约)$$

对样本的正常概率的分布绘制如下：

![image-20200206230832604](https://tva1.sinaimg.cn/large/0082zybpgy1gbn4nyox9vj30xw0jy40m.jpg)

如果按照真实标签值分别绘制好坏样本的分数分布，如下：

![image-20200206230910750](https://tva1.sinaimg.cn/large/0082zybpgy1gbn4nz5cmzj30ya0isq4c.jpg)

图中的虚线就是当前的阈值，0.5。改变阈值，会改变对应混淆矩阵各个单元格的数值。引入以下两个重要的比值$FPR$和$TPR$。

$$TPR=\dfrac{TP}{TP+FN}$$

这个指标代表所有的坏用户中模型预测出的比例，也就是**召回率**。

$$FPR=\dfrac{FP}{FP+TN}$$

这个值代表模型把多少比例的好用户误预测为坏用户，也就是**对好用户的误判率**。也是$1-sensitivity$

# 2. KS统计量和AUC量

根据以上计算出来的$TPR$和$FPR$可以计算出KS统计量和绘制出ROC曲线，ROC曲线与X轴围成的面积即为AUC。

KS统计量又称为**柯尔莫哥洛夫-斯米尔诺夫曲线**(kolmogorov-smirnov curve)，简称为k-s曲线。

绘制的方式如下：

将总体样本预测概率进行十等分，预测为「正常」的概率进行升序排列，计算每个区间的好坏样本的累积百分比，绘制出两者的差异，最大的差异值即为ks值，如下图所示。

![image-20200206233426760](https://tva1.sinaimg.cn/large/0082zybpgy1gbn4nzmrovj30za0jc764.jpg)



auc曲线的绘制方式和ks曲线的绘制方式类似，不同的是，auc是以FPR为x轴，TPR为y轴，绘制出两者的关系。

![image-20200206233616958](https://tva1.sinaimg.cn/large/0082zybpgy1gbn4nxb471j30oo0zu76s.jpg)

以上图为例子，在(a)图中，我们可以看出a点的FPR比B点小，且TPR高于B点，说明A点把更少的负样本误判，同时预测出更多的正样本，因此不同阈值下A点的性能要高于B点。由此看到(b)图，模型A的性能要好于模型B，也就是曲线越靠近左上方，模型对好坏的区分能力越强。我们一般以曲线与X轴围成的面积作为评判指标，称为AUC。



ROC和KS共同点都是可以评判一个模型的性能，不同点在于KS还可以找出最佳的阈值切分点。

ks值的大小与分箱的方式有关，随着你的分箱越细，有可能出现更高的ks值，但是不稳定。这一点可以结合相同分箱方式下的roc曲线可以看出，一般来说非过拟合的模型的roc曲线平滑，如果出现过拟合，有可能局部的ks很大，但是整体模型效果很差。

> 如果最终模型在训练集和测试集上面的ks表现没有超过5%的话，可以认为过拟合的风险不是很大。



ks在0.25以上具有一定的区分性，0.3效果比较好。

# 3. 提升图和洛伦兹曲线

提升图和洛伦兹曲线其实是同一个东西，目的都是看在引入模型以后相对于随机判断样本的好坏，性能提升了多少，相当于是一个投入产出比。

![image-20200206235934893](https://tva1.sinaimg.cn/large/0082zybpgy1gbn4nvzminj310o0qi42h.jpg)

具体做法是，对整体的概率进行十等分，预测每个样本违约的概率，按照概率降序排列，计算累积的违约百分比。对于随机筛选来说，因为是十等分，每个区间逾期的用户数随机应该占总体逾期用户数的10%，但对于模型来说，它给每个分数区间预测为坏样本的数量都是不同的，在高概率区间数量会更多，以此来表示模型的提升性能。

![image-20200206235414411](https://tva1.sinaimg.cn/large/0082zybpgy1gbn4nwvasdj30u00vu78l.jpg)

# 4. 稳定性

计算模型稳定性，一般用等频分箱要比等距分箱效果要更好。

psi一般在0.1以下算是比较好，0.25以下算是合格。