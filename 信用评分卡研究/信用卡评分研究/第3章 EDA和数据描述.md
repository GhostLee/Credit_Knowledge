# 引言

EDA称为**探索性数据分析**，该分析包括以下几个部分：

- 单变量的统计分布
- 自变量与自变量，自变量与因变量间的关联性
- 缺失值和极端值对模型的影响
- 预测变量中正常和违约的分布情况

# 1. 单变量统计量

单变量的统计量包括：

![image-20200207223527221](https://tva1.sinaimg.cn/large/0082zybpgy1gbo84s5y1aj30o20d2abq.jpg)

除了统计量，还有预测变量本身的分布，通常通过直方图分析

![image-20200207223701280](https://tva1.sinaimg.cn/large/0082zybpgy1gbo84tdtdtj311h0u0q5k.jpg)





# 2. 特征分析

特征分析主要是揭示预测变量与正常和违约分布的相关性，对预测变量进行分段，并且分析不同区间段的正常和违约的值的分布可以揭示违约状态和预测变量的关联性。

分段的方式包括等距分箱和等频分箱，底下就是等距分箱的其中一个例子。

![image-20200207224046550](https://tva1.sinaimg.cn/large/0082zybpgy1gbo84qx6rpj311a0jwwia.jpg)

#### 列联表

所谓列联表，就是各个单个的变量里面的各个类别的占比。如图就是变量X里面各个类别的占比。

![image-20200131230035612](https://tva1.sinaimg.cn/large/006tNbRwgy1gbgxryvriqj315i0j0q5d.jpg)



#### 极端值的识别

单一的信用评分卡开发过程中有2个基本依据：

1. 用来预测的自变量是因变量的函数
2. 用来建立单一评分卡模型的自变量是来自于同一个分布，也就是自变量的产生机制是一样的。



第二个条件的意思是，自变量的产生机制都是一样的，都是来源于某一个分布，这个分布不一定是我们所知道的分布，但是至少自变量之间的分布差异主要是来自于统计学上面的标准差。

如果是来自于这个分布以外的观测值就是异常值了。

异常值的来源一个是来自于分布以外，另外一个可能是记录错误，比如年龄里面记录了174，那这个根据常识很明显是记录的错误所导致的。

#### 当极端值占到了总体的10%

当极端值占到了总体的10%的时候，要注意这个时候就不能单纯把极端值当做是异常值除掉，而是这部分数值可能来源于另外一个群体，需要**分别对两个群体进行开发两个评分卡模型**。

#### 极端值的识别方法

1. 根据单变量的分布范围划分区间段。

正态分布距离均值的$±3\sigma$的范围内都是正常值的前提假设，这部分数据占了99.7%。对于分类变量或者顺序变量可以按照高于1%的总体占比都是正常的假设。该方法忽略了多个变量之间相互交叉影响，综合考虑的因素。但是用来初步对单变量进行筛选，是可以的。

2. 根据观察值建立稳健的逻辑回归模型。

![image-20200201000718509](https://tva1.sinaimg.cn/large/006tNbRwgy1gbgxrzehdcj30b70a1jrm.jpg)

如上图所示，按照观测值构建一个稳健的逻辑回归模型，正常点都应该是分布在逻辑回归模型曲线的附近，如果有远远偏离该稳健模型的则认为是异常值。这种方法考虑了多变量因素，但是需要依赖于稳健的逻辑回归模型，如果用于构建稳健的逻辑回归模型包含了异常值点，就会在预测的时候可能也会把极端值也预测为正常的。

3. 利用k聚类方法进行分群

该种方法可以综合考虑多变量因素以及分类，是以上两种方法的加强版。这种方法产生多个簇，依据的前提就是，相似表现的观测值会距离同一个聚类中心会越近。在分群以后再根据每个子群进行分别建立评分卡，该方法的关键在于初始化聚类中心的数目足够多，只要极端值都是相类似的，那么就会聚到一类。

4. 利用决策树识别出极端值

决策树的分裂结点对异常值不敏感，如果观测值重复出现在多个结点的一边的时候，并且距离分割节点比较远的时候可以认为很可能是极端值。这部分关键在于需要对决策树可视化。

# 3. 极端值的处理

极端值一般删除，或者是用相应的统计学变量代替，比如平均值，或者是中位数。