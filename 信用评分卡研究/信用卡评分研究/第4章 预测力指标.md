# 第4章 预测力指标

这个部分主要是评判自变量与因变量之间，自变量之间的预测能力。这里明确相关性和关联性的一些细微区别，相关性在统计学上更多表示是变量之间的线性关系，而关联性则不一定。前者更多是连续型变量与连续型变量，或者顺序变量与连续型变量的关系。

之所以要衡量自变量间的相关性，主要有两个原因：

1. 自变量之间有强相关性是逻辑回归模型本身不允许的，加入具有强共线性的自变量会导致模型本身不稳定。
2. 自变量具有相关性，说明有一些变量是重复的，或者说是包含的信息可以用更少的变量个数表达出来，这个时候可以用PCA主成分分析或者因子分析找出决定数据方差的最少自变量。





一般来说会有一个大的自变量的集合，这些是有关客户的所有的有关变量，而特征工程最终就是要筛选出一个预测力最强的自变量的最优子集。因此需要剔除掉那些与用户「正常/逾期」这个因变量预测力不够的变量。

![image-20200201121656054](https://tva1.sinaimg.cn/large/006tNbRwgy1gbgxs18cngj30y60a80u7.jpg)

## 符号

### 两个连续变量

皮尔逊相关系数和斯皮尔相关系数

### 两个分类变量

列联表计算各个类别的频率

![image-20200201122123831](https://tva1.sinaimg.cn/large/006tNbRwgy1gbgxrwondsj310c0ewt9y.jpg)

其中$$N=\sum_{i=1}^r\sum_{j=1}^cn_{ij}$$

### 分类变量和连续变量

对于分类变量X的每个类别，列出该类别下的y的所有值。

![image-20200201122750763](https://tva1.sinaimg.cn/large/006tNbRwgy1gbgxs3j1ejj310u0hywft.jpg)

计算以下几个指标：

每一行的总和，也就是x的每个类别的总和

$$y_i=\sum_{j=1}^ry_{ij}$$



第i行的平均值为$\bar{y_{i}}=\frac{y_i}{n_i}$，其中$n_i$为变量$X$该类别下的观测值个数。

总的y和为

$$y=\sum^{c}_{j=1}\sum^{r}_{i=1}y_{ij}$$



变量y的总体平均值为$\bar{y}=\frac{y}{n}$

根据总体平均值定义离差的平方和

$$STD=\sum_{i=1}^{r}(\sum_{j=1}^{n_i}(y_{ij}-\bar{y})^2)$$

定义行均平方差之和

总体平均值定义类别平均值的离差平方的加权总和：

$$SSTR=\sum_{i=1}^{r}n_i(\bar{y_i}-\bar{y})^2$$

行均的y的值离差平方的总和为：

$$SSE=\sum_{i=1}^{r}\sum_{j=1}^{n_i}(y_{ij}-\bar{y_i})$$

最后两个和的均值为

$$MSTR=\frac{SSTR}{r-1}$$

$$MSE=\frac{SSE}{N-r}$$

## 皮尔逊相关系数

跟协方差进行比较

给定两个连续的变量x和y，皮尔逊相关系数的计算方式如下：

$$\rho=\frac{\sum^{N}_{i=1}(x_i-\bar{x})(y_i-\bar{y})}{[\sum_{i=1}^{N}(x_i-\bar{x})^2\sum_{i=1}^{N}(y_i-\bar{y})^2]^{\frac{1}{2}}}$$

$x_i-\bar{x}$可以看作是自变量进行去中心化后的结果，也就是把中心移动到了原点。

皮尔逊相关系数可以理解成向量$[x_1,x_2,x_3,x_4,x_5……, x_N]$和$[y_1,y_2,y_3,y_4,y_5……, y_N]$这两个向量的余弦值，根据空间几何我们知道，两个向量越相近，夹角越小，余弦值越大，如果完全共线就是1，如果完全不相关就是夹角为90°，也就是余弦值为0。

![image-20200201140117459](https://tva1.sinaimg.cn/large/006tNbRwgy1gbgxs0alp8j30r20fidgu.jpg)



从另外一个角度看，皮尔逊相关系数的分子部分可以看成是去中心化后，x和y的乘积之和，反映出x和y的差异大小和方向，为正代表同方向变化，为负代表相反方向变化。

而分母相当于是对分子的值进行标准化的操作。

  ![image-20200201140757035](https://tva1.sinaimg.cn/large/006tNbRwgy1gbgxrxib01j30ua0u0jx4.jpg)



异常值对皮尔逊相关性系数影响很大，从上图可以看到value1和value2是相同的值，黄色圈圈是异常值，只要出现异常值，那么原本的相关性会从1降低到了0.72.

## 斯皮尔曼相关系数

斯皮尔曼相关系数和皮尔逊相关系数唯一的区别就是，斯皮尔曼相关系数是以变量所处的等级来代替具体的变量值。

$$\rho=\frac{\sum^{N}_{i=1}(R_i-\bar{R})(S_i-\bar{S})}{[\sum_{i=1}^{N}(R_i-\bar{R})^2\sum_{i=1}^{N}(S_i-\bar{S})^2]^{\frac{1}{2}}}$$

其中，$R_i$和$S_i$分别是第i个观测值的从小到大排序的等级，比如34，31和32，等级分别是3，1和2。

$\bar{R}$和$\bar{S}$分别是两个变量的等级的平均值。

相对于皮尔逊相关系数，斯皮尔曼相关系数对极端值不敏感。

## 皮尔森卡方统计量

皮尔森卡方统计量表示为$X^2$，用来计算分类变量和分类变量的关联性。其计算根据列联表4\.3得出。

![image-20200201122123831](https://tva1.sinaimg.cn/large/006tNbRwgy1gbgxrwondsj310c0ewt9y.jpg)

我们先计算出预期的单元数

$$\mu_{ij}=\frac{n_i\times n_j}{M}$$，这个代表第i行第j列的预期单元数

则皮尔森卡方统计量的表达式如下：

$$X^2=\sum_{i=1}^{r}\sum_{j=1}^{c}\frac{(n_{ij}-\mu_{ij})^2}{\mu_{ij}}$$

$\chi^2$是满足自由度为$df=(r-1)(c-1)$的卡方分布，也就是$\chi^2(X^2,(r-1)(c-1))$，其中$\chi^2$是满足卡方分布的累积分布概率函数。而两组变量独立的概率为$P_r(independence)=1-\chi^2(X^2,df)$

当i行，j列的单元数等于该预期单元数，也就是$n_{ij}=\mu_{ij}$的时候，$X^2=1$，对应的$\chi^2(X^2,df)$为0，独立的概率为1。

![image-20200201150303558](https://tva1.sinaimg.cn/large/006tNbRwgy1gbgxs2n5egj30u012e7dj.jpg)

 

## F检验

F检验是衡量连续型变量x和连续型变量y之间的关联程度，该检验通过计算$F^*$来实现。

也就是

$$F^*=\frac{MSTR}{MSE}$$

$F^*$代表x和y关联性强度的大小，越大说明关联程度越强。一般通过回归方程计算出$MSTR$和$MSE$后计算$F^*$。

## 信息值

woe化后，某个变量

$$IV=\sum_{i=1}^{N}(p_{0i}-p_{1i})ln(\frac{p_{0i}}{p_{1i}})$$

![image-20200201152206076](https://tva1.sinaimg.cn/large/006tNbRwgy1gbgxs1rw9hj312m08ijsh.jpg)

